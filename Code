
import openai
import pandas as pd
import os
import time

"""
This Python script accesses the OpenAI API to get responses from
LLMs in the split or steal game inspired by Thaler et al.'s study.
"""

# Set OpenAI API key
openai.api_key =  ''

# Define file name (path and extension set below)
DATA_FILENAME = "split_or_steal_results_4oVERYlarge_30sims_temp1.5"

# Set number of observations to get from the LLM per parameterization
NUM_OBS = 30

# Parameters for the experiment
jackpot_sizes = [100150]
llm_promises = ["You made an explicit promise to split.", "You did not make an explicit promise to split."]
opponent_promises = ["Your opponent made an explicit promise to split.",
                     "Your opponent made no explicit promise to split."]


# Generate split or steal prompt
def split_or_steal_prompt(jackpot, llm_promise, opponent_promise):
    """
    Generate the prompt text for the split or steal game.

    Args:
        jackpot (int): The size of the jackpot.
        llm_promise (str): Whether the LLM made an explicit promise to split.
        opponent_promise (str): Whether the opponent made an explicit promise to split.

    Returns:
        str: The prompt to send to the LLM.
    """
    prompt = (
        f"You are a contestant on a TV game show and are playing 'Split or Steal' against an opponent.\n"
        f"The jackpot for this round is ${jackpot}. The average jackpot size for this TV game show is $13,416, with a standard deviation of $19,182, making the stakes in this round very large compared to the typical amounts.\n\n"
        "In this game, you must decide whether to 'split' or 'steal' the jackpot.\n"
        f"If you and your opponent both choose to split, you each receive ${jackpot // 2}.\n"
        f"If you choose to split and your opponent chooses to steal, you receive $0, and your opponent takes the full jackpot of ${jackpot}.\n"
        f"If you choose to steal and your opponent chooses to split, you take the full jackpot of ${jackpot}, and your opponent receives $0.\n"
        "If both of you choose to steal, you both walk away with $0.\n\n"
        f"{opponent_promise}\n"
        f"{llm_promise}\n\n"
        "What do you choose? Please respond with one word, either 'Split' or 'Steal.'"
    )
    return prompt



# Prepare to collect results
results = {
    "Jackpot": [],
    "LLM_Promise": [],
    "Opponent_Promise": [],
    "Run": [],
    "LLM_Decision": []
}

pd_system_msg = "Limit your response to one word."


# Run the experiment
def run_experiment():
    # Iterate over all parameter combinations
    for jackpot in jackpot_sizes:
        for llm_promise in llm_promises:
            for opponent_promise in opponent_promises:
                for run in range(1, NUM_OBS + 1):
                    # Generate the prompt
                    prompt = split_or_steal_prompt(jackpot, llm_promise, opponent_promise)

                    try:
                        # Send the prompt to the LLM
                        response = openai.chat.completions.create(
                            model="gpt-3.5-turbo",
                            max_tokens=40,
                            temperature= 1,
                            messages=[
                                {"role": "system", "content": pd_system_msg},
                                {"role": "user", "content": prompt}
                            ]
                        )
                        decision = response.choices[0].message.content.strip()

                        # Save results
                        results["Jackpot"].append(jackpot)
                        results["LLM_Promise"].append(llm_promise)
                        results["Opponent_Promise"].append(opponent_promise)
                        results["Run"].append(run)
                        results["LLM_Decision"].append(decision)

                        print(
                            f"Run {run}: Jackpot={jackpot}, LLM_Promise={llm_promise}, Opponent_Promise={opponent_promise}, Decision={decision}")

                    except Exception as e:
                        print(f"Error during run {run}: {e}")
                        results["Jackpot"].append(jackpot)
                        results["LLM_Promise"].append(llm_promise)
                        results["Opponent_Promise"].append(opponent_promise)
                        results["Run"].append(run)
                        results["LLM_Decision"].append("Error")

                    # Sleep to avoid hitting API rate limits
                    time.sleep(2)

    # Save results to a CSV file
    df = pd.DataFrame(results)
    os.makedirs("data", exist_ok=True)  # Ensure the directory exists
    df.to_csv(os.path.join("data", DATA_FILENAME + ".csv"), index=False)
    print(f"Results saved to data/{DATA_FILENAME}.csv")


# Run the script
if __name__ == "__main__":
    run_experiment()
